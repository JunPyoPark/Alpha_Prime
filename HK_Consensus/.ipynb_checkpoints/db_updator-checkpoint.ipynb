{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 한경 컨센서스 데이터 마이닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "import fake_useragent\n",
    "import time\n",
    "import json\n",
    "from slacker import Slacker\n",
    "token = 'xoxp-293906112689-293906113169-414841439126-fd8b1b9a38627ad4e233bc990bdf5d2d'  # hk_consensus app\n",
    "slack = Slacker(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 크롤링에 필요한 Parameter_dict(table_dict) 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_dict = {}\n",
    "# table_dict['Business']={}\n",
    "table_dict['business']={}\n",
    "# table_dict['Industry']={}\n",
    "table_dict['industry']={}\n",
    "table_dict['derivative']={}\n",
    "table_dict['economy']={}\n",
    "table_dict['market']={}\n",
    "table_dict['stock_bad_price']={}\n",
    "table_dict['stock_bad_updown']={}\n",
    "table_dict['stock_good_price']={}\n",
    "table_dict['stock_good_updown']={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_dict['business']['param'] = {'skinType':'business'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_dict['industry']['param'] = {'skinType':'industry'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_dict['market']['param'] = {'skinType':'market'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_dict['derivative']['param'] = {'skinType':'market'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_dict['economy']['param'] = {'skinType':'economy'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_dict['stock_good_price']['param'] = {'skinType':'stock_good'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_dict['stock_good_updown']['param'] = {'skinType':'stock_good', 'up_down_type':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_dict['stock_bad_price']['param'] = {'skinType':'stock_bad'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_dict['stock_bad_updown']['param'] = {'skinType':'stock_bad', 'up_down_type':2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## table_dict 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business': {'param': {'skinType': 'business'}},\n",
       " 'industry': {'param': {'skinType': 'industry'}},\n",
       " 'derivative': {'param': {'skinType': 'market'}},\n",
       " 'economy': {'param': {'skinType': 'economy'}},\n",
       " 'market': {'param': {'skinType': 'market'}},\n",
       " 'stock_bad_price': {'param': {'skinType': 'stock_bad'}},\n",
       " 'stock_bad_updown': {'param': {'skinType': 'stock_bad', 'up_down_type': 2}},\n",
       " 'stock_good_price': {'param': {'skinType': 'stock_good'}},\n",
       " 'stock_good_updown': {'param': {'skinType': 'stock_good', 'up_down_type': 2}}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base URL Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://hkconsensus.hankyung.com/apps.analysis/analysis.list'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 카테고리 별 processing 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기업 카테고리에 해당하는 processing 함수\n",
    "def process_business_data(navigator,recent_date):\n",
    "    table = navigator.find('tbody')\n",
    "    # 리포트 링크 추출\n",
    "    link_list = []\n",
    "    for i in table.find_all('tr'): # td search\n",
    "        try:\n",
    "            report_address = str(i.find_all('td')[8].find_all('a')[0]).split()[1][6:-1]\n",
    "            link_list.append('http://hkconsensus.hankyung.com' + report_address)\n",
    "        except:\n",
    "            link_list.append('')\n",
    "            continue\n",
    "\n",
    "    table = '<table>'+str(table)+'</table>'\n",
    "    df_table = pd.read_html(str(table))[0] \n",
    "    df_table = df_table.drop([7,8],axis=1)\n",
    "    df_table.columns = ['dt', 'title', 'predict_price', 'opinion', 'author', 'issued_by','report_link']\n",
    "    df_table['report_link'] = link_list\n",
    "    \n",
    "    df_table['code'] = df_table['title'].apply(lambda x : 'A' + x.split(')')[0][-6:])\n",
    "    df_table['company'] = df_table['title'].apply(lambda x : x.split(')')[0][:-7])\n",
    "    \n",
    "    ### select only new data ###\n",
    "    checker = df_table['dt'] > recent_date\n",
    "    # checker.all() : boolean type, if false while loop exit!\n",
    "    return checker.all(), df_table[checker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파생 카테고리에 해당하는 processing 함수\n",
    "def process_derivative_data(navigator,recent_date):\n",
    "    table = navigator.find('tbody')\n",
    "    # 리포트 링크 추출\n",
    "    link_list = []\n",
    "    for i in table.find_all('tr'): # td search\n",
    "        try:\n",
    "            report_address = str(i.find_all('td')[5].find_all('a')[0]).split()[1][6:-1]\n",
    "            link_list.append('http://hkconsensus.hankyung.com' + report_address)\n",
    "        except:\n",
    "            link_list.append('')\n",
    "            continue\n",
    "\n",
    "    table = '<table>'+str(table)+'</table>'\n",
    "    df_table = pd.read_html(str(table))[0] \n",
    "    df_table = df_table.drop([5],axis=1)\n",
    "    df_table.columns = ['dt', 'title',  'author', 'issued_by','report_link']\n",
    "    df_table['report_link'] = link_list\n",
    "\n",
    "    ### select only new data ###\n",
    "    checker = df_table['dt'] > recent_date\n",
    "    # checker.all() : boolean type, if false while loop exit!\n",
    "    return checker.all(), df_table[checker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경제 카테고리에 해당하는 processing 함수\n",
    "def process_economy_data(navigator,recent_date):\n",
    "    table = navigator.find('tbody')\n",
    "    # 리포트 링크 추출\n",
    "    link_list = []\n",
    "    for i in table.find_all('tr'): # td search\n",
    "        try:\n",
    "            report_address = str(i.find_all('td')[5].find_all('a')[0]).split()[1][6:-1]\n",
    "            link_list.append('http://hkconsensus.hankyung.com' + report_address)\n",
    "        except:\n",
    "            link_list.append('')\n",
    "            continue\n",
    "\n",
    "    table = '<table>'+str(table)+'</table>'\n",
    "    df_table = pd.read_html(str(table))[0] \n",
    "    df_table = df_table.drop([5],axis=1)\n",
    "    df_table.columns = ['dt', 'title',  'author', 'issued_by','report_link']\n",
    "    df_table['report_link'] = link_list\n",
    "\n",
    "    ### select only new data ###\n",
    "    checker = df_table['dt'] > recent_date\n",
    "    # checker.all() : boolean type, if false while loop exit!\n",
    "    return checker.all(), df_table[checker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 산업 카테고리에 해당하는 processing 함수\n",
    "def process_industry_data(navigator,recent_date):\n",
    "    table = navigator.find('tbody')\n",
    "    # 리포트 링크 추출\n",
    "    link_list = []\n",
    "    for i in table.find_all('tr'): # td search\n",
    "        try:\n",
    "            report_address = str(i.find_all('td')[6].find_all('a')[0]).split()[1][6:-1]\n",
    "            link_list.append('http://hkconsensus.hankyung.com' + report_address)\n",
    "        except:\n",
    "            link_list.append('')\n",
    "            continue\n",
    "\n",
    "    table = '<table>'+str(table)+'</table>'\n",
    "    df_table = pd.read_html(str(table))[0] \n",
    "    df_table = df_table.drop([2,6],axis=1)\n",
    "    df_table.columns = ['dt', 'title',  'author', 'issued_by','report_link']\n",
    "    df_table['report_link'] = link_list\n",
    "    \n",
    "    df_table['keyword'] = df_table['title'].apply(lambda x : x.split('-')[0])\n",
    "\n",
    "    ### select only new data ###\n",
    "    checker = df_table['dt'] > recent_date\n",
    "    # checker.all() : boolean type, if false while loop exit!\n",
    "    return checker.all(), df_table[checker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마켓 카테고리에 해당하는 processing 함수\n",
    "def process_market_data(navigator,recent_date):\n",
    "    table = navigator.find('tbody')\n",
    "    # 리포트 링크 추출\n",
    "    link_list = []\n",
    "    for i in table.find_all('tr'): # td search\n",
    "        try:\n",
    "            report_address = str(i.find_all('td')[5].find_all('a')[0]).split()[1][6:-1]\n",
    "            link_list.append('http://hkconsensus.hankyung.com' + report_address)\n",
    "        except:\n",
    "            link_list.append('')\n",
    "            continue\n",
    "\n",
    "    table = '<table>'+str(table)+'</table>'\n",
    "    df_table = pd.read_html(str(table))[0] \n",
    "    df_table = df_table.drop([5],axis=1)\n",
    "    df_table.columns = ['dt', 'title',  'author', 'issued_by','report_link']\n",
    "    df_table['report_link'] = link_list\n",
    "    \n",
    "\n",
    "    ### select only new data ###\n",
    "    checker = df_table['dt'] > recent_date\n",
    "    # checker.all() : boolean type, if false while loop exit!\n",
    "    return checker.all(), df_table[checker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 processing 함수\n",
    "def process_data(navigator,recent_date):\n",
    "    table = navigator.find('tbody')\n",
    "    \n",
    "    table = '<table>'+str(table)+'</table>'\n",
    "    df_table = pd.read_html(str(table))[0] \n",
    "    df_table.columns = ['dt', 'title', 'writer', 'issued_by', 'current', 'prev']\n",
    "    \n",
    "    df_table['code'] = df_table['title'].apply(lambda x : 'A' + x.split(')')[0][-6:])\n",
    "    df_table['company'] = df_table['title'].apply(lambda x : x.split(')')[0][:-7])\n",
    "        \n",
    "    ### select only new data ###\n",
    "    checker = df_table['dt'] > recent_date\n",
    "    # checker.all() : boolean type, if false while loop exit!\n",
    "    return checker.all(), df_table[checker]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DB Connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "con=sqlite3.connect('consensus.db')\n",
    "cursor=con.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fake User Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = fake_useragent.UserAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mozilla/5.0 (Windows; U; MSIE 9.0; Windows NT 9.0; en-US)'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing Data from HK consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business  last date is  2018-10-19\n",
      "20 consensuses updated\n",
      "20 consensuses updated\n",
      "20 consensuses updated\n",
      "20 consensuses updated\n",
      "20 consensuses updated\n",
      "20 consensuses updated\n",
      "20 consensuses updated\n",
      "20 consensuses updated\n",
      "20 consensuses updated\n",
      "20 consensuses updated\n",
      "20 consensuses updated\n",
      "20 consensuses updated\n",
      "20 consensuses updated\n",
      "20 consensuses updated\n",
      "20 consensuses updated\n",
      "20 consensuses updated\n",
      "20 consensuses updated\n",
      "20 consensuses updated\n",
      "0 consensuses updated\n",
      "business  table update finished!!!\n",
      "industry  last date is  2018-10-19\n",
      "20 consensuses updated\n",
      "20 consensuses updated\n",
      "20 consensuses updated\n",
      "20 consensuses updated\n",
      "20 consensuses updated\n",
      "20 consensuses updated\n",
      "15 consensuses updated\n",
      "industry  table update finished!!!\n",
      "derivative  last date is  2018-10-19\n",
      "20 consensuses updated\n",
      "20 consensuses updated\n",
      "20 consensuses updated\n",
      "14 consensuses updated\n",
      "derivative  table update finished!!!\n",
      "economy  last date is  2018-10-19\n",
      "17 consensuses updated\n",
      "economy  table update finished!!!\n",
      "market  last date is  2018-10-19\n",
      "20 consensuses updated\n",
      "20 consensuses updated\n",
      "20 consensuses updated\n",
      "14 consensuses updated\n",
      "market  table update finished!!!\n",
      "stock_bad_price  last date is  2018-10-19\n",
      "20 consensuses updated\n",
      "20 consensuses updated\n",
      "20 consensuses updated\n",
      "20 consensuses updated\n",
      "20 consensuses updated\n",
      "5 consensuses updated\n",
      "stock_bad_price  table update finished!!!\n",
      "stock_bad_updown  last date is  2018-10-19\n",
      "5 consensuses updated\n",
      "stock_bad_updown  table update finished!!!\n",
      "stock_good_price  last date is  2018-10-19\n",
      "20 consensuses updated\n",
      "9 consensuses updated\n",
      "stock_good_price  table update finished!!!\n",
      "stock_good_updown  last date is  2018-10-18\n",
      "10 consensuses updated\n",
      "stock_good_updown  table update finished!!!\n",
      "--------------------All Update Complete--------------------\n"
     ]
    }
   ],
   "source": [
    "con=sqlite3.connect('consensus.db')\n",
    "\n",
    "for i in table_dict.keys(): # 카테고리별 Loop 돌리기\n",
    "    count = 0\n",
    "    attachments_dict = {}\n",
    "    # 현재 저자된 DB에서 최근 날짜 확인\n",
    "    sql_state = \"SELECT * FROM \" + i +\" ORDER BY dt DESC LIMIT 1\"\n",
    "    df = pd.read_sql(sql_state, con, index_col='dt')\n",
    "    recent_date = df.index[0]\n",
    "\n",
    "    print(i, ' last date is ', recent_date)\n",
    "    \n",
    "    # 최근 날짜 이후 ~ 현재 까지의 데이터 파싱\n",
    "    param = table_dict[i]['param']\n",
    "    page_num=0\n",
    "    checker = True \n",
    "    while(checker):\n",
    "        page_num += 1\n",
    "        #load\n",
    "        time.sleep(0.5 + np.random.rand()/5)\n",
    "        param['now_page'] = page_num\n",
    "        res = requests.get(url, params=param,\n",
    "                   headers={'User-agent': agent.random})\n",
    "        #process_data\n",
    "        navigator = BeautifulSoup(res.content.decode('euc-kr'), 'html.parser')\n",
    "\n",
    "        if 'stock' in i.split('_'): # 키워드 분류\n",
    "            try:\n",
    "                (checker, df_table) = process_data(navigator, recent_date)\n",
    "            except:\n",
    "                continue\n",
    "        else:\n",
    "            try:\n",
    "                func_name = 'process_' + i + '_data'\n",
    "                (checker, df_table) = locals()[func_name](navigator, recent_date)\n",
    "            except:\n",
    "                continue       \n",
    "\n",
    "        # update db\n",
    "        #save_to_sql\n",
    "        df_table.set_index('dt').to_sql(i,con,if_exists='append')\n",
    "        count = count + len(df_table)\n",
    "        \n",
    "        print(len(df_table), 'consensuses updated')\n",
    "        try:\n",
    "            attachments_dict['title'] = attachments_dict['title'] + '\\n' + str(len(df_table)) + ' consensuses updated'\n",
    "        except:\n",
    "            attachments_dict['title'] = str(len(df_table)) + ' consensuses updated'\n",
    "    \n",
    "    attachments_dict['pretext'] = i + ' db table : ' + str(count) + ' cnosensuses updated complete'\n",
    "    \n",
    "    print(i,' table update finished!!!')\n",
    "    attachments = [attachments_dict]\n",
    "    slack.chat.post_message(channel=\"#transactions\", text=None, attachments=attachments)\n",
    "\n",
    "print('--------------------All Update Complete--------------------')\n",
    "slack.chat.post_message('#transactions', '--------------------All Update Complete--------------------')\n",
    "con.commit()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting the Log Message to Slack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from slacker import Slacker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "개발자용 토큰 받기\n",
    "\n",
    "http://egloos.zum.com/mcchae/v/11244865"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://trello-attachments.s3.amazonaws.com/5b29ec749cfb0d90ada47d03/5bd5c4cc004c7d04020e1854/432fb2404a585135461f304b4e6292b9/image.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = 'xoxp-293906112689-293906113169-414841439126-fd8b1b9a38627ad4e233bc990bdf5d2d'  # hk_consensus app\n",
    "slack = Slacker(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "attachments_dict = dict()\n",
    "attachments_dict['pretext'] = \"attachments 블록 전에 나타나는 text\"\n",
    "attachments_dict['title'] = \"다른 텍스트 보다 크고 볼드되어서 보이는 title\"\n",
    "attachments_dict['title_link'] = \"https://corikachu.github.io\"\n",
    "attachments_dict['fallback'] = \"클라이언트에서 노티피케이션에 보이는 텍스트 입니다. attachment 블록에는 나타나지 않습니다\"\n",
    "attachments_dict['text'] = \"본문 텍스트! 5줄이 넘어가면 *show more*로 보이게 됩니다.\"\n",
    "attachments_dict['mrkdwn_in'] = [\"text\", \"pretext\"]  # 마크다운을 적용시킬 인자들을 선택합니다.\n",
    "attachments = [attachments_dict]\n",
    "\n",
    "slack.chat.post_message(channel=\"#channel\", text=None, attachments=attachments, as_user=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "attachments_dict = dict()\n",
    "attachments_dict['pretext'] = 'pretext'\n",
    "attachments_dict['title'] = 'title'\n",
    "attachments_dict['title'] = attachments_dict['title'] + '\\n' + 'ddddd'\n",
    "attachments = [attachments_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<slacker.Response at 0x2184c9c1e10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slack.chat.post_message('#transactions', 'hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<slacker.Response at 0x2184cf33da0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slack.chat.post_message(channel=\"#transactions\", text=None, attachments=attachments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
